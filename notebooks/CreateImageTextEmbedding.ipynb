{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWUh9Rryifdh"
   },
   "source": [
    "# **Imagic Image-Text Embedding Notebook**\n",
    "\n",
    "This notebook generates image-text embeddings using Imagic framework. It supports single image-text embeddings and batch embedding creation for multiple images and texts. The notebook is structured to align with the objectives outlined in the thesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WkXfNrhifdi"
   },
   "source": [
    "## **1. Environment Setup**\n",
    "Install necessary libraries and clone the required repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q3GrQYwSifdj"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Reouth/Movie-Character-Identification-With-Perosnalized-Generative-Models.git\n",
    "\n",
    "%pip install -qq git+https://github.com/huggingface/diffusers.git\n",
    "%pip install -q accelerate\n",
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVnS7kScifdj"
   },
   "source": [
    "## **2. Import Libraries**\n",
    "Load necessary Python libraries and scripts."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Change directory to cloned repository\n",
    "os.chdir('/content/Movie-Character-Identification-With-Perosnalized-Generative-Models')\n",
    "\n",
    "from models.Diffusion import ImagicTrain\n",
    "import handlers import ImageHandler"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **3. Configure Authentication**\n",
    "Login to Hugging Face to access the Stable Diffusion model."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from huggingface_hub import notebook_login\n",
    "!git config --global credential.helper store\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiEmG7NVifdk"
   },
   "source": [
    "## **4. Mount Google Drive**\n",
    "Store and retrieve files from Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKWHYOS_ifdk"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJqY5FW-ifdk"
   },
   "source": [
    "## **5. Configuration**\n",
    "Set model and training parameters.\n",
    "\n",
    "*   text_inputs specifies prompts for generating embeddings.\n",
    "*   images_folder_path defines where input images are stored.\n",
    "*   output_path determines where embeddings will be saved.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cnqw1N7Qifdk"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODEL_NAME = \"CompVis/stable-diffusion-v1-4\"\n",
    "SEED = 42\n",
    "RESOLUTION = 1024\n",
    "EMB_LEARNING_RATE = 1e-3\n",
    "LEARNING_RATE = 2e-6\n",
    "EMB_TRAIN_STEPS = 2000\n",
    "MAX_TRAIN_STEPS = 4000\n",
    "\n",
    "# Path configurations\n",
    "text_inputs = [\"a photo of a person\"]  # Add text prompts\n",
    "images_folder_path = \"/content/drive/MyDrive/thesis_OO_SD/ex_machina/ID_images\"\n",
    "output_path = \"/content/drive/MyDrive/thesis_OO_SD/ex_machina/Imagic_embeddings/\"\n",
    "os.makedirs(output_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **6. Image-Text Embedding**\n",
    "Generate embeddings for image and text prompt."
   ],
   "metadata": {
    "id": "UMy5fb4NkeUP"
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_imagic_embedding(image_path, text, output_folder, model_name=MODEL_NAME):\n",
    "    \"\"\"\n",
    "    Trains Imagic embeddings for a single image-text pair.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        text (str): Text prompt for embedding.\n",
    "        output_folder (str): Directory to save the embeddings.\n",
    "        model_name (str): Pretrained model name.\n",
    "    \"\"\"\n",
    "    if os.path.isdir(os.path.join(output_folder, \"vae\")):\n",
    "        print(f\"Embeddings already exist for {image_path} with text: {text}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Training embeddings for {image_path} with text: {text}\")\n",
    "    !accelerate launch ImagicTrain.py \\\n",
    "        --pretrained_model_name_or_path={model_name} \\\n",
    "        --output_dir={output_folder} \\\n",
    "        --input_image={image_path} \\\n",
    "        --target_text=\"{text}\" \\\n",
    "        --seed={SEED} \\\n",
    "        --resolution={RESOLUTION} \\\n",
    "        --mixed_precision=\"fp16\" \\\n",
    "        --use_8bit_adam \\\n",
    "        --gradient_accumulation_steps=1 \\\n",
    "        --emb_learning_rate={EMB_LEARNING_RATE} \\\n",
    "        --learning_rate={LEARNING_RATE} \\\n",
    "        --emb_train_steps={EMB_TRAIN_STEPS} \\\n",
    "        --max_train_steps={MAX_TRAIN_STEPS} \\\n",
    "        --gradient_checkpointing\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title Single Image-Text Embedding\n",
    "\n",
    "single_text = text_inputs[0] #single text/first text in text_inputs list\n",
    "single_image = os.path.join(images_folder_path, \"Mitzi_2.jpg\") #single image from folder\n",
    "train_imagic_embedding(image_path, text_imagic, output_folder_path)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title Batch Image-Text Embeddings\n",
    "for text in text_inputs:\n",
    "    text_path = text.replace(' ', '_')\n",
    "    if text == \"\":\n",
    "        text_path = \"no_text_prompt\"\n",
    "    text_folder_path = os.path.join(output_path, text_path)\n",
    "    os.makedirs(text_folder_path, exist_ok=True)\n",
    "\n",
    "    for image_name, _, image_path in ImageHandler.upload_images(images_folder_path):\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        output_folder_path = os.path.join(text_folder_path, image_name)\n",
    "        train_imagic_embedding(image_path, text, output_folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
